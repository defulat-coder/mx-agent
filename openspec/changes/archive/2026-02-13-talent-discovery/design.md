## Context

当前 HR 系统已有完整的员工基础数据（绩效、培训、IDP、九宫格、岗位变动、考勤），但缺少技能、教育、项目、证书等维度数据，且所有分析工具仅做"查询聚合"，不具备交叉分析和主动发现能力。

现有技术栈：FastAPI + Agno + SQLAlchemy(aiosqlite) + OpenAI-compatible LLM (GLM-4)。所有 Tool 通过 Agno 注册，由 HR Agent 调用。

## Goals / Non-Goals

**Goals:**
- 新增 4 个数据模型补齐人才画像维度
- 构建 6 个人才发现场景，采用规则筛选 + LLM 分析的混合模式
- 发现 Tool 与现有 talent_dev 工具体系一致，使用 `td_` 前缀，复用相同权限体系
- 新增知识库指导 LLM 按统一评估框架分析

**Non-Goals:**
- 不做实时指标计算或数据管道（所有分析在查询时实时计算）
- 不做员工自助录入接口（数据录入由 HR 管理后台完成，本期只做查询和分析）
- 不做机器学习模型训练（用规则 + LLM 替代）
- 不引入新的外部依赖

## Decisions

### 1. 混合分析模式：规则筛选 + LLM 生成

**选择**: 规则引擎做候选人筛选，LLM 做综合分析报告生成

**理由**: 纯规则缺乏灵活性（无法理解非结构化评语），纯 LLM 不稳定且 token 消耗大（把全员数据喂给 LLM 不现实）。混合模式先用 SQL 缩小范围到候选人列表，再对候选人的多维数据调用 LLM 生成报告。

**替代方案**: 纯规则方案（放弃 LLM 分析）— 开发快但输出僵化；纯 LLM 方案 — 灵活但成本高且不可控。

### 2. 发现 Tool 的数据流

```
Tool 调用
  → services/discovery.py（规则筛选，返回候选人 + 结构化数据）
  → Tool 层组装 prompt，调用 LLM 生成分析文本
  → 返回结构化数据 + LLM 分析文本
```

**选择**: LLM 调用放在 Tool 层而非 Service 层

**理由**: Service 层保持纯数据操作（可测试、可复用），LLM 调用作为 Tool 的增强输出。Agno Agent 本身就在 LLM 对话上下文中，发现 Tool 返回结构化数据后，Agent 可以直接用这些数据回答用户，LLM 分析报告作为 Tool 返回值的一部分由 Agent 自行整合。

实际上，由于 Agno Agent 调用 Tool 后会将 Tool 返回结果交给 LLM 做最终回答，**发现 Tool 只需返回结构化的候选人数据和关键指标，由 Agent 的 LLM 直接生成分析**，无需在 Tool 内部额外调用 LLM。知识库（Skill）提供评估框架，引导 Agent 的 LLM 按统一标准分析。

### 3. 新模型放在 `app/models/hr/` 下

**选择**: 与现有 HR 模型放同一目录，不新建子目录

**理由**: 4 个新模型都是员工维度数据，与 Employee 同级，保持一致性。

### 4. 发现服务独立为 `services/discovery.py`

**选择**: 新建 `services/discovery.py` 而非放入 `services/hr.py`

**理由**: `services/hr.py` 已包含大量 CRUD 函数，发现逻辑涉及多表交叉查询和规则判断，复杂度不同，独立文件更清晰。新模型的基础 CRUD 仍放 `services/hr.py`。

### 5. 技能数据缺失时的降级策略

**选择**: Tool 4（岗位适配）和 Tool 6（团队能力短板）在技能数据为空时返回提示信息而非报错

**理由**: 系统上线后技能数据需逐步录入，不能因为数据不全就阻塞其他发现场景。前 3 个 Tool 完全基于现有数据即可运行。

## Risks / Trade-offs

- **规则阈值硬编码** → 将阈值提取为知识库中的可配置参数，后续可调整
- **LLM 分析质量不稳定** → 通过知识库提供详细评估框架和示例，约束输出格式
- **大量员工时性能** → 发现查询涉及多表 JOIN，SQLite 可能在千人级别出现性能问题 → 当前规模足够，后续可加缓存或迁移数据库
- **技能数据冷启动** → 岗位适配和团队短板两个场景依赖技能数据，上线初期功能受限 → 优雅降级，明确提示
